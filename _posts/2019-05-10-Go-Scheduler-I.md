---
layout:     post
title:      "[译]Go调度I-操作系统调度器"
subtitle:   "Go Scheduling I - OS Scheduler"
date:       2019-05-9 21:00:00
author:     "会飞的蜗牛"
header-img: "img/go-scheduler-i.jpg"
tags:
    - 操作系统调度器
    - OS Scheduler
---



## 简介

Go调度器的设计和实现使我们的多线程 Go 程序更加高效，并且性能更好。这主要归功于Go调度程序与操作系统（OS）调度程序的互相协作。但是，多线程Go程序的设计和实现是否与OS调度程序完全契合不是重点。重要的是对系统调度器和Go调度器，以及它们是如何正确地设计多线程程序，有一个全面且深入的理解。

这篇由多部分组成的文章将重点介绍调度器更高级别的机制和语义。我将提供足够的信息，让你可以通过图像来理解它们是如何工作的，这样你在需要的时候可以做出更好的工程决策。因为机制和语义构成了您所需的基础知识的最关键部分。

## 系统调度
操作系统调度器是一个复杂的软件。它们必须考虑运行时的硬件的布局和设置，包括但不限于多处理器核心，CPU缓存和`NUMA`。只有全面考虑这些知识，调度程序才能进可能高效地工作。但最棒的是，你无需深入研究这些主题，仍然可以深入了解操作系统调度器是如何工作的。

本质上来讲，程序只是一系列按顺序执行的机器指令。那谁来干这个活呢，就是操作系统使用一个叫做线程的东西。线程负责顺序执行分配给他的一系列指令，直到没有更多指令为止。这就是为什么我把线程叫做“执行流”的原因。

你运行的每个程序都会创建一个进程，并且每个进程都会有一个初始线程。线程又可以创建更多的线程。所有这些线程都是相互独立运行，这样负责这些线程的就是调度层，而不是进程层。线程也可以并发执行（每个线程轮流占用 CPU 核），或者并行（同时运行在不同的核心上）。线程为了安全，本地，独立的运行指令，需要维护它们自己的状态。

当有线程可以被执行的时候，系统调度器需要调度线程去运行，确保核心不会处于空闲状态。同时创造一个所有线程同时执行的假象。创造这些假象的时候，调度器优先调度高优先级的线程运行，但是，也不能因为这样而把低优先级的线程饿死。因此，调度器需要减少调度延迟，尽可能的最初最快最智能的决策。

为了达到这个目的，需要大量的算法，但是幸运的是，这个领域已经积累了数十年的发展与经验。为了更好的理解这一切，接下来我们来看几个重要的概念。

## 并行指令
程序计数器(`PC`)，有时候也叫指令指针(`IP`)，线程利用它来跟踪下一条要执行的指令。对大部分处理器上来说，`PC` 指向的是下一条指令，而不是当前指令。

图1
![图1](https://www.ardanlabs.com/images/goinggo/92_figure1.jpeg)

<https://www.slideshare.net/JohnCutajar/assembly-language-8086-intermediate>

如果你曾看过Go程序调用栈，可能已经注意到了，每一行最后的16进制数字，比如Listing1的`+0x39`和`0x72`.

Listing1

```
goroutine 1 [running]:
   main.example(0xc000042748, 0x2, 0x4, 0x106abae, 0x5, 0xa)
       stack_trace/example1/example1.go:13 +0x39                 <- LOOK HERE
   main.main()
       stack_trace/example1/example1.go:8 +0x72                  <- LOOK HERE    
```

这些数字就表示**PC**值与相应函数顶部的偏移量，+0x39表示线程在example函数里下一个要执行的指令，如果程序没有崩溃的话。如果控制权回到主函数中，则主函数中的下一条指令是0+x72PC偏移量。更重要的是，指针前面的指令是当前正在执行的指令。

 
 
Those numbers represent the PC value offset from the top of the respective function. The +0x39 PC offset value represents the next instruction the Thread would have executed inside the example function if the program hadn’t panicked. The 0+x72 PC offset value is the next instruction inside the main function if control happened to go back to that function. More important, the instruction prior to that pointer tells you what instruction was executing.

下面是Listing1栈调用对应的代码：

Listing2

```
https://github.com/ardanlabs/gotraining/blob/master/topics/go/profiling/stack_trace/example1/example1.go

07 func main() {
08     example(make([]string, 2, 4), "hello", 10)
09 }

12 func example(slice []string, str string, i int) {
13    panic("Want stack trace")
14 }

```

十六进制数+0x39表示示例函数内的一条指令的 PC 偏移量，该指令位于函数的起始指令后面第57条(10进制)。接下来，我们用 objdump 来看一下汇编指令。找到第57条指令，注意，runtime.gopanic那一行。

Listing3

```
$ go tool objdump -S -s "main.example" ./example1
TEXT main.example(SB) stack_trace/example1/example1.go
func example(slice []string, str string, i int) {
  0x104dfa0        65488b0c2530000000    MOVQ GS:0x30, CX
  0x104dfa9        483b6110              CMPQ 0x10(CX), SP
  0x104dfad        762c                  JBE 0x104dfdb
  0x104dfaf        4883ec18              SUBQ $0x18, SP
  0x104dfb3        48896c2410            MOVQ BP, 0x10(SP)
  0x104dfb8        488d6c2410            LEAQ 0x10(SP), BP
    panic("Want stack trace")
  0x104dfbd        488d059ca20000        LEAQ runtime.types+41504(SB), AX
  0x104dfc4        48890424              MOVQ AX, 0(SP)
  0x104dfc8        488d05a1870200        LEAQ main.statictmp_0(SB), AX
  0x104dfcf        4889442408            MOVQ AX, 0x8(SP)
  0x104dfd4        e8c735fdff            CALL runtime.gopanic(SB)
  0x104dfd9        0f0b                  UD2              <--- 这里是 PC(+0x39)
```
**记住: PC 是下一个指令，而不是当前指令。** Listing3是基于`amd64`汇编指令的一个很好的例子，该`Go`程序的线程负责顺序执行。

## 线程状态

另一个重要的概念就是线程状态，它描述了调度器在线程中的角色。线程可以在以下三种状态之一：等待中(`Waiting`)，可执行(`Runnable`)，正在执行(`Executing`)。

等待中(`Waiting`)：这种状态意味着线程是暂停的，等待某些资源以便可以继续执行。通常来说原因可能有以下这些，等待硬件资源(磁盘，网络)，操作系统(系统调用)或者同步调用(原子操作，锁)。这些延迟是程序性能差的根源之一。

可执行(`Runnable`)：这种状态意味着线程想要拥有核心的时间片，以便可以执行分配给它的机器指令。如果你的程序有很多线程想要拥有时间片，那么线程要等待的时间就更长了。同理，单个线程拥有的独立时间片就会变少，因为有更多的线程在竞争cpu时间片。这种类型的延迟同样也是程序性能差的根源之一。

正在执行(`Executing`)：这种状态意味着线程正占有核心，并在执行它的机器指令。应用相关的工作将要完成。这是大家都想看到的。

## 工作类型
线程可以做两种类型的工作，第一种是`CPU-Bound`，第二种是`IO-Bound`。

`CPU-Bound`：这种工作永远不会让线程处于等待状态，因为这是一项不断进行计算的工作。例如，计算Pi的第N位的线程就是 CPU-Bound。

`IO-Bound`：这种类型的工作将会导致程序进入等待状态。主要组成是请求获取网络资源或者进行系统调用。需要访问数据库的线程就是 IO-Bound。我也要把同步状态(锁，原子操作)也包括进来，因为这也会导致线程等待。

## 上下文切换
如果你的程序运行在诸如Linux，Mac，Windows等抢占式调度器OS上，那么你就需要注意以下几点：

首先，调度工作是不可预测的，你不知道你的程序线程会什么时候被调度。线程的优先级和事件（例如网络收发数据）混在一起，使得无法确定调度程序将选择做什么以及什么时候做。

其次，这意味着你不能基于一些过去经历过但不能保证每次发生的行为来写代码。这会很容易让你觉得这是确定的行为，因为我曾经见过上千次这样的事情发生。如果应用程序需要确定性，就必须控制线程同步和协调。

CPU上的线程交换的物理行为被叫做上下文切换。当调度器把正在执行的线程换下来，取而代之的是可执行的线程，这就是正在发生一个上下文切换。从运行队列中选中的线程被置为正在运行状态，而被取出的线程则切换到可执行状态（如果还能执行），或者进入等待中状态（如果是因为IO等待而被取代）。

上下文切换非常昂贵，因为这需要把线程从核心上换入换出。一次上下文切换的延迟取决于不同的因素，在1000-1500ns之间。考虑到CPU能够合理的每秒大约分配12个指令（平均值），这样一次上下文切换大约需要花费掉12k到18k条指令的时间。因此，一次上下文切换将会浪费掉能执行大量指令的时间。

如果你的程序是IO-Bound类型，那么上下文切换将会是一个优势。一旦一个线程进入等待状态，另一个可执行的线程就会取代它原来的位置。这样核心可以一直工作。这就是调度最重要的一个方面。当有可执行状态线程的时候，不会允许核心进入空闲状态。

如果你的程序是CPU-Bound类型，那么上下文切换将是性能噩梦。因为线程一直有工作可做，但是上下文切换却是让线程停止工作。这种情况与 IO-Bound 类型的工作形成了鲜明对比。

## 少即是多
在计算机技术初期，处理器还只有一核，调度工作还不会太复杂。因为任意时刻只有一个线程在工作。其思想是定义一个调度程序周期，并尝试在这段时间内执行所有可运行线程。很简单：将调度周期除以可执行的线程数。

举例来说，如果你定义调度周期为10ms，同时程序有2个线程，这样每个线程将得到5ms的执行时间，如果有5个线程，则每个线程得到2ms的时间。然而，如果你有1000个线程呢？显然，给每个线程分配10微秒的时间并不能正常工作，因为你还需要花费大量的时间在上下文切换上。

你需要限制时间片的长度。在最后一个场景中，如果最小时间片是 2ms，并且有 1000 个线程，那么调度器周期需要增加到 2s(秒)。如果有 10000 个线程，那么调度器周期就是 20s。在这个简单的例子中，如果每个线程使用它的全时间片，那么所有线程运行一次需要花费 20s。

你要明白这还是真实世界最简单的场景。还有更多更复杂的场景需要调度器做决策的时候需要考虑的因素。你可以控制应用程序中线程的个数。当这里有更多的线程需要考虑，加上还有IO-Bound情形需要考虑，这会导致混乱和不可预知的行为。这样就需要更长的时间区调度和执行。

这就是为什么游戏的规则叫做“小就是多”。更少的可执行状态线程意味着更少的调度开销和更多的线程工作时间。反之，更多的可执行线程则意味着每个线程的工作时间更短，这就意味你的工作需要更长的时间来完成。

## 寻找平衡点
你必须在主机拥有的核心数和线程数之间找到一个平衡点，以便程序达到最佳性能。当说到怎么设置这个平衡点，线程池是一个很好的解决方案，这点我将在第二章节展示，但是Go语言并不需要。我觉得这是Go语言做的很不错的一个事情，让多线程应用开发变得更容易。

当在NT上写一个跟数据库打交道的web服务时，每个核心上跑3个线程总会魔法般得获得最好的性能。换句话说，每个核心上跑3个线程能最小化上下文切换延迟，最大化线程执行时间。这样我就知道如何创建一个IOCP线程池。

如果程序在一个核心上跑2个线程，需要花费更多的时间来完成任务，因为核心还有空闲时间。如果跑4个线程同样也会花费更长的时间，因为花在上线文切换的时间太多了。所以魔法般的3个线程并发总能获得最佳性能。

但是如果你的程序同时需要做许多不同类型的工作呢？那会产生很多不同且不持续的延迟。也许是因为有许多不同的系统级的事件需要处理。当然也有可能找到这个魔法数字来获得最佳性能，但是这样会复杂的多。

## CPU缓存
由于从主存中获取数据会有很高的延迟（100到300个时钟周期），这样处理器和核心就需要本地缓存来缓存硬件线程需要的数据。而从缓存获取数据延迟非常低（大约3到40个时钟周期）。如今，性能一个重要的方面，就是如何高效的给处理器提供数据来降低延迟。编写多线程应用程序也需要考虑 CPU 缓存的机制。

图2
![tu2](https://segmentfault.com/img/bVbfsoO?w=1085&h=835)

处理器和内存之间的数据交换需要通过`cache line`，`cache line`是在主存和高速缓存系统之间交换的 64 字节内存块。每个核心都有自己的`cache line`副本，这意味着硬件使用值语意。这就是为什么多线程应用程序中内存的变化会造成性能噩梦。

当多线程并行运行在不同的核心上并去获取相同的或相邻的数据值时，它们会去相同的`cache line`获取数据。在任何核心上跑的任何线程都会获取到相同的`cache line`副本。

图3
![tu3](https://www.ardanlabs.com/images/goinggo/92_figure3.png)

如果某个核心上的一个线程对其`cache line`的副本进行了更改，那么同一`cache line`的所有其他副本都必须标记为dirty的。当线程尝试对`dirty cache line`进行读写访问时，需要向主存访问(大约 100 到 300 个时钟周期)来获得`cache line`的新副本。

也许这对于双核的处理器来说还不是什么大事，但是如果是32核处理器上并行跑32个线程并同时去同一 `cache line`获取数据，结果又会怎么样呢？对于16核的双处理器又是什么情况呢？这只会让情况更糟，因为还需要加上处理器之间的延迟。应用程序将会在主存中周转，性能将会大幅下降，而你却不明白这是为什么。

这被称为缓存一致性问题，还引入了错误共享等问题。在编写可能会改变共享状态的多线程应用程序时，必须考虑缓存系统。

## 调度决策场景
假如我要求你基于我给的信息写一个操作系统调度器。思考一下这个你必须考虑的场景。记住，这只是调度器做调度决策必须考虑的趣事之一。

启动你的应用，创建主线程并跑在核心1上。当线程开始执行指令，由于需要数据，正在检索`cache line`。现在，线程又创建了一个新的线程，由于并发的需要。这就会有几点问题：

一旦线程被创建，并准备运行，调度器应该怎么做？

1. 通过上下文切换把主线程从核心1上取出？这么做有助于提高性能，因为新的线程需要的新数据已经被缓存起来。但是主线程却还没有用完它的时间片。
2. 新线程等待核心1在主线程完成之前变为可用？线程没有运行，但一旦启动，获取数据的延迟将被消除。
3. 线程等待下一个可用的核心？这意味着所选核心的cache line将被刷新、检索和复制，从而导致延迟。然而，线程将启动得更快，主线程可以完成它的时间片。

有意思吗？这就是调度器做调度决策时必须考虑的有趣问题。幸运的是，这不是我做的。我能告诉你的是，如果有一个核心是空闲的，它就会被使用。你希望线程在可运行的时候去运行。

## 结论
本文的第一部分深入介绍了在编写多线程应用程序时需要考虑的关于线程和系统调度器的问题。这些是 Go 调度器也要考虑的事情。在下一篇文章中，我将解析 Go 调度器的语义以及它们如何与这些信息相关联，并通过一些示例程序来展示。

## 参考链接
<https://www.ardanlabs.com/blog/2018/08/scheduling-in-go-part1.html>

